# Awesome Worth More Attention Deep Learning Papers 
[![Awesome](https://awesome.re/badge-flat.svg)](https://awesome.re)

A curated list of hidden gems in the field of Artificial Intelligence. Inspired by [Awesome Deep Learning Papers](https://github.com/terryum/awesome-deep-learning-papers), [Deep Learning Papers Reading Roadmap](https://github.com/floodsung/Deep-Learning-Papers-Reading-Roadmap) and so many more.

We believe that there are many papers in AI/DL that go under the radar of most readers, whether it's because there wasn't a big name author in it or the timing of the publication just wasn't right. Many lists already expose the well known and industry standard papers. But we want to broaden the list of topics within the AI domain by exploring lesser-known papers with novel ideas.

## Contributing
Got a paper that you like a lot but it never got to see the light of day? Feel free to open up an [issue](https://github.com/Nurture-AI/Worth-More-Attention/issues) or [pull request](https://github.com/Nurture-AI/Worth-More-Attention/pulls) with the title of the paper and why you think it's a hidden gem. 

- Scalable training of artificial neural networks with adaptive sparse connectivity inspired by network science [paper](https://nurture.ai/papers/scalable-training-of-artificial-neural-networks-with-adaptive-sparse-connectivity-inspired-by-network-science)
- Self-Attention with Relative Position Representations [paper](https://nurture.ai/papers/self-attention-with-relative-position-representations)
- Constituency Parsing with a Self-Attentive Encoder [paper](https://nurture.ai/papers/constituency-parsing-with-a-self-attentive-encoder)
- Position-aware Self-attention with Relative Positional Encodings for Slot [paper](https://nurture.ai/papers/position-aware-self-attention-with-relative-positional-encodings-for-slot-filling)
- Improving Language Understanding by Generative Pre-Training [paper](https://blog.openai.com/language-unsupervised/)
- Learning to Segment Everything [paper](https://nurture.ai/papers/learning-to-segment-every-thing)
- DrMAD: Distilling Reverse-Mode Automatic Differentiation for Optimizing Hyperparameters of Deep Neural Networks [paper](https://nurture.ai/papers/drmad-distilling-reverse-mode-automatic-differentiation-for-optimizing-hyperparameters-of-deep-neural-networks)


## Maintainers
This list is currently maintained by the AI Reseach Team @Nurture.ai.
